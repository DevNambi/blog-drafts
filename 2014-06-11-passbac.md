---
author: DevNambi
date: 2014-06-11
layout: post
slug: pass-analytics
title: PASS Business Analytics 2014 - Recap
meta-description: 
- pass
- keynote
- microsoft
- sqlpass
- passbac
- visualization
- analytics
- keynotes
- david mccandless
- strata conference
---

A few weeks ago I had the privilege of attending of the [PASS Business Analytics conference](http://www.sqlpass.org/bac/2014/Home.aspx) (PASS BAC) with 750 other data geeks in San Jose, CA. 

The last conference I had attended was Strata (LINKME), another data-to-decisions shindig. I've decided to compare and contrast the two.



## Similarities


#### Data Geeks, Joined

The SQL PASS community and the Strata communities have some things in common:

* There's a multitude of specialties
* Everyone is trying to learn more and try new things
* There's a vocal and helpful community on Twitter. 
* Many of the most brilliant engineers, researchers and developers strive to be helpful.
* There are huge numbers of vendors arguing that their tools can solve business problems.

#### Luck

Everyone wants to get more out of their data. Businesses are *desperate* to do so. Data scientists, analysts and engineers are *paid* to work with data every day. 

We are in the enviable position of being well paid to do the work we love.We're outliers; most such industries pay poorly: [*teaching, global health, cancer research, nursing, cooking, music, art, English, history, biology, physics, etc.*](http://www.salon.com/2014/06/01/help_us_thomas_piketty_the_1s_sick_and_twisted_new_scheme/?source=newsletter)

#### Data Cleansing


One of the best events was Wednesday's unconference session. It was a rare chance to crowdsource discussion topics and expertise. 

One of the problems *everyone* has is cleaning up data. That's not surprising; surveys consistently show that 80%+ of time is spent cleaning up data in a data-analysis project or when doing scientific research (ADD LINKS). 

This is, oddly, an area with comparatively few tools (LINKME). There were 3 options discussed:

**Rules-Based Cleansing**

This is the first approach everybody thinks of when they clean up data. They find patterns in good data, and use *rules* (IF, THEN, CASE) to clean up data. This is often the 'T' (transform) in an ETL codebase. 

This approach, however, has some flaws. It's developer-centric, and often requires extensive testing. It's hard to debug, especially if there's a data pipeline with multiple, sequential data-cleaning steps. It also does not handle new errors or edge cases well, so it requires ongoing developer support to maintain.

**Vendor Cleansing**

This is the second approach. Some data-cleaning problems are so common that many businesses face them (addresses). 

In that case, a logical solution is to buy a third-party product or service, and have it do the heavy lifting. After all, there's no reason thousands of companies need to build their own address-parsing pipelines.

However, this approach doesn't make sense when the data to clean is internal (custom) or sensitive (SSNs, banking data, medical records). 

**Math-Based Cleansing**

The third approach is my favorite: **use math**. (IMAGE)

There's an entire specialty in statistics devoted to detecting when data is missing or an outlier that can be safely discarded. (LINKME). More to the point, it lets an analyst know whether the missing/outlier data meaningfully changes the result of a problem. This is what scientific research has done for *decades*. 

The other part of this approach is maching learning. If we assign probabilities to each data element (that it's valid, that it's X or Y part of an address, etc), we can build a machine learning model to predict how likely a data element is what we want. 

However, there are very few tools for this approach thus far. So you need a machine learning developer (data engineer), and they're awfully rare.

(IMAGE: wave of the future)

## Differences

#### Techniques

After a disappointing [Data Science Bingo](https://github.com/tdhopper/Data-Science-Conference-Bingo) score in the Thursday morning keynote, I set out to find out how common certain tools and techniques were in my audience. I asked 33 people which technologies they knew about or used...

(USE CHART VIZ INSTEAD)

* SQL: 33
* Hadoop: 33
* Hive: 7
* D3.js: 2
* Scikit-Learn: 2
* Kaggle.com: 1
* Apache Spark: 0
* Cloudera Impala: 0

In addition to asking about specific tools, I also asked about tool-neutral techniques for analyzing and processing data.

(USE CHART VIZ INSTEAD)

* Decision trees: 6
* Neural networks: 3
* Association rules / market-basket analysis: 3
* Logistic regression: 2
* Eigenvectors / eigenvalues: 2
* TF-IDF: 1
* Ensembling: 1
* Perceptron: 1
* The Iris Data Set: 0
* Random forests: 0
* MCMC: 0
* HyperLogLog: 0
* Bloom filters: 0
* Lambda architecture: 0
* Visual 'encoding': 0
* Dimensionality reduction: 0
* The Curse of Dimensionality: 0
* ROC curves, AUC: 0


(LINKME - ADD LINKS)

The folks attending may be *future* data scientists, but this sample suggests a distinct gap in their machine learning skills. I found only a few promising analysts in my survey.



#### Technology Stacks

PASS BAC is a Microsoft-centric conference on data analysis; that's its main limitation. Imagine having a conference on car safety with only American car makers.

For example, the most common data-friendly command-line tools are Python and R. They have huge numbers of libraries and support reproducible research. Microsoft has Excel, which has terrible library support, and *no* support for reproducible research. It's contributed to world-changing, fascist-government-inspiring screwups (LINK TO ROGOFF SCREWUP, GOLDEN DAWN).

If you think about it, code is a precise form of communication *to other people* as well as to machines. The only practical way to do command-line data analysis on the MS stack is to run a Linux VM in Azure. Oops

(IMAGE: awkward)


#### Audience Goals


Strata and PASS BAC have one **huge** difference: their implicit messages are different.

* The implicit goal for PASS BAC is: *empower* analysts to make data-driven decisions for their business.
* The implicit goal for Strata is: *deprecate* analysts. Give business customers the tools, and they'll make your business successful.

This shows up a lot in different lessons. PASS BAC sessions are predominantely about how to help analysts solve X or Y problem.


Strata sessions are about solving X problem, even if the result is an automated process or data product (Google Search results, Netflix movie recommendations, Hotmail's spam filter, and LinkedIn's "People You May Know" suggestions).

PASS BAC assumes that there's a data-hungry, precocious analysts who will make better choices with pretty charts. Evidence (FIND IT) suggests that's a dangerous assumption to make.

*The maturity curve of BI is long, but it bends towards automation.*


This points out an organizational challenge: how do we empower people to solve challenges that are beyond them? There are 4 options.

**Option A**: dumb down the problem so people can solve it using their existing skills <br />
**Option B**: educate people so they can tackle the problem. <br />
**Option C**: use a different approach so there are no people in the first place <br />
**Option D**: tackle a different problem

Tool-building vendors take the first approach. Their value proposition is "we solve your biggest challenge using our deus-ex-machine tool." That sounds a lot better than "your staff's outdated skills are your biggest challenge, we just help out with a smaller problem.".

**Communication**

Another common challenge I heard discussed was communication lapses. A battle of perspectives, priority and resources between developers, business folks, and IT admins is still ongoing for the PASS BAC attendees. 

There were some common approaches that people liked:

* Fix the incentives. People behave according to their incentives.
* Remember that **the first feature of any product is that it works**. 
* Don't expect you can overhaul company culture. If an engineering org is enlightened enough to build clean code the first time, stay. If they value refactors at a sane pace, stay. Otherwise: run away, quickly.


#### Industries

Strata was heavily represented by startups, academia, and scientific researchers; PASS BAC had established industries, such as insurance, finance, and retail.

The audiences are different, with different goals. Strata felt fast, even frantic at times. Startups are always rushed. Scientific research never has enough resourcing.

PASS BAC was slower, more methodical. The goal of the audience isn't to 'disrupt' an industry, but to defend one. They have far more resources, and assume they have more time. 

**Laggards**

I wonder how often companies late to the world of data-driven decisions do some things:

* Make difficult, contrary decisions because the data says so
* Present data contrary to what upper management wants to hear, with a suggestion to do something different
* Have senior managers / executives make course changes based on new data.
* Run controlled experiments or do econometrics analysis to find causal relationships between business variables/ideas.

A *huge* part of an organization improving using data is the cultural approach decision-makers make with it. If decision makers are just looking for confirmation of their ideas, then stay away. Far away.



### David McCandless
 
The best keynote, by far, was David McCandless ([Information Is Beautiful](informationisbeautiful.net), @DavidMc (LINKME)) . 

I was struck by how he used visualizations to illustrate the gaps in human perception. For example, humans can't easily understand what *one billion* looks like. It's too large to grasp. So he made a visualization comparing relative amounts over a billion (IMAGE).

The same problem exists for a million lines of code. Or the probabilistic results in the Drake Equation. It makes sense to use visuals to communicate these results, since we use 75% of our neurons to process what we see (LINKME).

Data visualization, therefore, is a type of human communication. Its goals are the same as any kind of communication: clarity, emotional connection, overcoming gaps in perception and language. If you want to learn the principles of data visualization, study communication.

Telling *stories* with data, though, is journalism. It's about inquiry, discovery, and narrative delivery. If you want to learn how to tell stories with data, study journalism. 

There are a few common things to do and avoid.


**Ways to Succeed**

* Work on a useful question or problem. Work on something interesting.
* Be trustworthy. Act with integrity.
* Remember form. Your results must look good, and have a certain standard of quality.
* Remember function. Your results must be easy to use

**Ways to Fail**

* When you visualize a complex data set, you make a complex graphic. Doesn't solve it.
* Circular diagrams aren't that usable. 
* Cartograms...hard to get the data out. Very hard to compare.
* Design is really about removing things, cleaning down to a functional essence.


### Next

Despite having a fun time speaking and chatting at PASS BAC, I doubt I'll go back. It's a useful conference for BI practitioners in established industries, looking for incremental improvements. There's nothing wrong with that, but it's not for me. 

I can network better at a local meetup (LINK), learn more by doing my own research (LINK TO XKCD) or reading a good research paper (LINK TO Chris Re's feature selection paper), and reach a wider audience with a blog post. 